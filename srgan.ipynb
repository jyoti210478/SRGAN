{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-22T11:15:51.767315Z","iopub.status.busy":"2024-08-22T11:15:51.766945Z","iopub.status.idle":"2024-08-22T11:16:06.446906Z","shell.execute_reply":"2024-08-22T11:16:06.445822Z","shell.execute_reply.started":"2024-08-22T11:15:51.767283Z"},"trusted":true},"outputs":[],"source":["# Enable mixed precision training\n","from tensorflow.keras import mixed_precision\n","mixed_precision.set_global_policy('mixed_float16')\n","\n","\n","import tensorflow as tf\n","from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, LeakyReLU, PReLU, Add, UpSampling2D\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.applications import VGG19\n","import numpy as np\n","from tensorflow.keras.backend import clear_session\n","import gc"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-21T15:01:34.909922Z","iopub.status.busy":"2024-08-21T15:01:34.909628Z","iopub.status.idle":"2024-08-21T15:02:07.230458Z","shell.execute_reply":"2024-08-21T15:02:07.229336Z","shell.execute_reply.started":"2024-08-21T15:01:34.909896Z"},"trusted":true},"outputs":[],"source":["pip install memory-profiler"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-21T15:02:07.232454Z","iopub.status.busy":"2024-08-21T15:02:07.232080Z","iopub.status.idle":"2024-08-21T15:02:07.241716Z","shell.execute_reply":"2024-08-21T15:02:07.240625Z","shell.execute_reply.started":"2024-08-21T15:02:07.232421Z"},"trusted":true},"outputs":[],"source":["from memory_profiler import profile"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-21T15:02:07.243155Z","iopub.status.busy":"2024-08-21T15:02:07.242878Z","iopub.status.idle":"2024-08-21T15:02:07.252879Z","shell.execute_reply":"2024-08-21T15:02:07.251796Z","shell.execute_reply.started":"2024-08-21T15:02:07.243132Z"},"trusted":true},"outputs":[],"source":["def residual_block(x, filters):\n","    # Save the input as a skip connection\n","    skip = x\n","    \n","    # First convolutional layer\n","    x = Conv2D(filters, kernel_size=3, strides=1, padding='same')(x)\n","    x = BatchNormalization(momentum=0.8)(x)\n","    x = PReLU(shared_axes=[1, 2])(x)\n","    \n","    # Second convolutional layer\n","    x = Conv2D(filters, kernel_size=3, strides=1, padding='same')(x)\n","    x = BatchNormalization(momentum=0.8)(x)\n","    \n","    # Add the skip connection (residual)\n","    x = Add()([skip, x])\n","    \n","    return x\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-21T15:02:07.254937Z","iopub.status.busy":"2024-08-21T15:02:07.254568Z","iopub.status.idle":"2024-08-21T15:02:07.265835Z","shell.execute_reply":"2024-08-21T15:02:07.264991Z","shell.execute_reply.started":"2024-08-21T15:02:07.254903Z"},"trusted":true},"outputs":[],"source":["def build_generator():\n","    #Input Shape: The input to the generator is an image with three color channels (RGB). The None values indicate that the height and width of the image can be any size.\n","    input_layer = Input(shape=(None, None, 3))\n","\n","    # Pre-residual block\n","\n","    #Convolutional Layer: The first layer of the generator is a convolutional layer with 64 filters, a 9x9 kernel size, and a stride of 1. This layer extracts low-level features from the input image.\n","    #PReLU Activation: PReLU (Parametric ReLU) is an activation function that introduces non-linearity, allowing the model to learn more complex patterns. The shared_axes=[1, 2] ensures that the parameters are shared across the spatial dimensions (height and width).\n","    x = Conv2D(64, kernel_size=9, strides=1, padding='same')(input_layer)\n","    x = PReLU(shared_axes=[1, 2])(x)\n","    residual = x\n","\n","    # Residual blocks\n","\n","    #Residual Connection: The initial convolutional output x is saved as residual to be used later in the network.\n","    #Residual Blocks: The generator uses 16 residual blocks. Each block adds a skip connection, allowing the network to learn residual features instead of direct mappings. These blocks enhance the capacity of the generator to capture finer details without losing the original low-resolution features.\n","    for _ in range(16):\n","        residual = residual_block(residual, 64)\n","\n","    # Post-residual block\n","\n","    #Convolutional Layer: After passing through the residual blocks, the output is passed through another convolutional layer with a 3x3 kernel size and 64 filters.\n","    #Batch Normalization: Normalizes the activations to improve stability and convergence during training.\n","    #Skip Connection: The output of this layer is added back to the original residual (input to the residual blocks). This step further emphasizes the learned residuals.\n","    x = Conv2D(64, kernel_size=3, strides=1, padding='same')(residual)\n","    x = BatchNormalization(momentum=0.8)(x)\n","    x = Add()([x, residual])\n","\n","    # Upsampling blocks\n","\n","    #Upsampling: To upscale the image, two upsampling blocks are used. Each block doubles the spatial dimensions (height and width) of the image using bilinear interpolation.\n","    #Convolutional Layer: After upsampling, the output is passed through a convolutional layer with 256 filters and a 3x3 kernel size. This layer helps in refining the upscaled image.\n","    #PReLU Activation: Adds non-linearity after upsampling to help the model learn complex features.\n","    for _ in range(2):\n","        x = UpSampling2D(size=2)(x)\n","        x = Conv2D(128, kernel_size=3, strides=1, padding='same')(x)\n","        x = PReLU(shared_axes=[1, 2])(x)\n","\n","\n","    #Final Convolutional Layer: The final layer of the generator is a convolutional layer with 3 filters (one for each RGB channel) and a 9x9 kernel size. This layer generates the final high-resolution image.\n","    #Tanh Activation: The tanh activation function is used to ensure that the output pixel values are in the range [-1, 1], which is typical for image data normalization.\n","    output_layer = Conv2D(3, kernel_size=9, strides=1, padding='same', activation='tanh')(x)\n","    \n","    return Model(input_layer, output_layer)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-21T15:02:07.267260Z","iopub.status.busy":"2024-08-21T15:02:07.266936Z","iopub.status.idle":"2024-08-21T15:02:07.280177Z","shell.execute_reply":"2024-08-21T15:02:07.279306Z","shell.execute_reply.started":"2024-08-21T15:02:07.267226Z"},"trusted":true},"outputs":[],"source":["def build_discriminator():\n","    input_layer = Input(shape=(None, None, 3))\n","    x = input_layer\n","    def conv_block(x, filters, strides=1, bn=True):\n","        x = Conv2D(filters, kernel_size=3, strides=strides, padding='same')(x)\n","        if bn:\n","            x = BatchNormalization(momentum=0.8)(x)\n","        x = LeakyReLU(alpha=0.2)(x)\n","        return x\n","\n","    x = conv_block(input_layer, 64, bn=False)\n","    x = conv_block(x, 64, strides=2)\n","    x = conv_block(x, 128)\n","    x = conv_block(x, 128, strides=2)\n","#     x = conv_block(x, 256)\n","#     x = conv_block(x, 256, strides=2)\n","#     x = conv_block(x, 512)\n","#     x = conv_block(x, 512, strides=2)\n","\n","    # Calculate flattened size after defining input shape\n","    x = tf.keras.layers.GlobalAveragePooling2D()(x)  # Flatten using GlobalAveragePooling2D\n","    flattened_size = x.shape[1]  # Get the flattened size\n","    # x = tf.keras.layers.Flatten()(x)\n","    x = tf.keras.layers.Dense(1024, input_shape=(flattened_size,))(x)  # Use the calculated flattened size\n","    x = LeakyReLU(alpha=0.2)(x)\n","    output_layer = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n","\n","    return Model(input_layer, output_layer)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-21T15:02:07.283629Z","iopub.status.busy":"2024-08-21T15:02:07.283298Z","iopub.status.idle":"2024-08-21T15:02:07.293418Z","shell.execute_reply":"2024-08-21T15:02:07.292666Z","shell.execute_reply.started":"2024-08-21T15:02:07.283598Z"},"trusted":true},"outputs":[],"source":["def build_vgg():\n","    vgg = VGG19(weights=\"imagenet\", include_top=False)\n","    vgg.trainable = False\n","    model = Model(inputs=vgg.input, outputs=vgg.get_layer(\"block5_conv4\").output)\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-21T15:02:07.294927Z","iopub.status.busy":"2024-08-21T15:02:07.294616Z","iopub.status.idle":"2024-08-21T15:02:07.303131Z","shell.execute_reply":"2024-08-21T15:02:07.302105Z","shell.execute_reply.started":"2024-08-21T15:02:07.294903Z"},"trusted":true},"outputs":[],"source":["def compile_srgan(generator, discriminator, vgg):\n","    # Compile the discriminator\n","    discriminator.compile(optimizer=tf.keras.optimizers.Adam(0.0002, 0.5), loss='binary_crossentropy', metrics=['accuracy'])\n","\n","    # Build and compile the SRGAN\n","    input_lr = Input(shape=(None, None, 3))\n","    generated_hr = generator(input_lr)\n","    features = vgg(generated_hr)\n","    discriminator.trainable = False\n","    validity = discriminator(generated_hr)\n","\n","    srgan_model = Model(inputs=input_lr, outputs=[validity, features])\n","    srgan_model.compile(loss=['binary_crossentropy', 'mse'], loss_weights=[1e-3, 1], optimizer=tf.keras.optimizers.Adam(0.0002, 0.5))\n","\n","    return srgan_model\n"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-08-21T15:02:07.304868Z","iopub.status.busy":"2024-08-21T15:02:07.304359Z","iopub.status.idle":"2024-08-21T15:02:07.317394Z","shell.execute_reply":"2024-08-21T15:02:07.316449Z","shell.execute_reply.started":"2024-08-21T15:02:07.304842Z"},"trusted":true},"outputs":[],"source":["@profile\n","def train_srgan(generator, discriminator, srgan_model, epochs, batch_size, train_data):\n","    for epoch in range(epochs):\n","        clear_session()\n","        gc.collect()\n","        for batch in range(len(train_data) // batch_size):\n","            # Select a random batch of images\n","            idx = np.random.randint(0, len(train_data), batch_size)\n","            imgs_lr, imgs_hr = zip(*[train_data[i] for i in idx])\n","\n","            imgs_lr = np.array(imgs_lr)\n","            imgs_hr = np.array(imgs_hr)\n","\n","            # Generate high-resolution images\n","            generated_hr = generator.predict(imgs_lr)\n","\n","            # Train the discriminator\n","            real = np.ones((batch_size, 1))\n","            fake = np.zeros((batch_size, 1))\n","\n","            d_loss_real = discriminator.train_on_batch(imgs_hr, real)\n","            d_loss_fake = discriminator.train_on_batch(generated_hr, fake)\n","            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n","\n","            # Train the generator\n","            image_features = vgg.predict(imgs_hr)\n","            g_loss = srgan_model.train_on_batch(imgs_lr, [real, image_features])\n","\n","        print(f\"Epoch: {epoch+1}, D Loss: {d_loss}, G Loss: {g_loss}\")\n","\n","        if (epoch + 1) % 200 == 0:\n","            generator.save(f'srgan_generator_epoch_{epoch+1}.keras')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2024-08-21T15:02:07.318873Z","iopub.status.busy":"2024-08-21T15:02:07.318527Z","iopub.status.idle":"2024-08-21T15:02:09.807264Z","shell.execute_reply":"2024-08-21T15:02:09.806491Z","shell.execute_reply.started":"2024-08-21T15:02:07.318842Z"},"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[],"source":["# Instantiate the models\n","generator = build_generator()\n","discriminator = build_discriminator()\n","vgg = build_vgg()\n","generator.summary()\n","discriminator.summary()\n","# Compile the SRGAN\n","srgan_model = compile_srgan(generator, discriminator, vgg)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2024-08-21T15:02:09.808705Z","iopub.status.busy":"2024-08-21T15:02:09.808416Z","iopub.status.idle":"2024-08-21T15:02:09.838960Z","shell.execute_reply":"2024-08-21T15:02:09.838051Z","shell.execute_reply.started":"2024-08-21T15:02:09.808682Z"},"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[],"source":["srgan_model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-21T15:02:09.840389Z","iopub.status.busy":"2024-08-21T15:02:09.840095Z","iopub.status.idle":"2024-08-21T15:02:09.849374Z","shell.execute_reply":"2024-08-21T15:02:09.848521Z","shell.execute_reply.started":"2024-08-21T15:02:09.840363Z"},"trusted":true},"outputs":[],"source":["import os\n","import numpy as np\n","from tensorflow.keras.preprocessing.image import img_to_array, load_img\n","\n","def load_images(lr_dir, hr_dir, img_size):\n","    lr_images = sorted(os.listdir(lr_dir))\n","    hr_images = sorted(os.listdir(hr_dir))\n","    \n","    # Slice the lists to get only the first n images\n","    lr_images_n = lr_images[:855]\n","    hr_images_n = hr_images[:855]\n","\n","    train_data = []\n","\n","    for lr_img, hr_img in zip(lr_images_n, hr_images_n):\n","        # Load low-res and high-res images\n","        lr_image = load_img(os.path.join(lr_dir, lr_img), target_size=img_size)\n","        hr_image = load_img(os.path.join(hr_dir, hr_img), target_size=(img_size[0] * 4, img_size[1] * 4))\n","\n","        # Convert to arrays and normalize\n","        lr_image = img_to_array(lr_image) / 255.0\n","        hr_image = img_to_array(hr_image) / 255.0\n","\n","        # Append the pair (LR, HR) to the training data list\n","        train_data.append((lr_image, hr_image))\n","\n","    return train_data\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-21T15:02:09.851061Z","iopub.status.busy":"2024-08-21T15:02:09.850642Z","iopub.status.idle":"2024-08-21T15:02:13.351895Z","shell.execute_reply":"2024-08-21T15:02:13.350841Z","shell.execute_reply.started":"2024-08-21T15:02:09.851029Z"},"trusted":true},"outputs":[],"source":["# Specify the directories and image size for low-resolution images\n","img_size = (64, 64)  # Adjust as needed\n","lr_dir = '/kaggle/input/raw-data/Raw Data/low_res'\n","hr_dir = '/kaggle/input/raw-data/Raw Data/high_res'\n","\n","# Load images and create the train_data array\n","train_data = load_images(lr_dir, hr_dir, img_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-21T15:02:13.354177Z","iopub.status.busy":"2024-08-21T15:02:13.353343Z","iopub.status.idle":"2024-08-21T15:02:13.360912Z","shell.execute_reply":"2024-08-21T15:02:13.359941Z","shell.execute_reply.started":"2024-08-21T15:02:13.354138Z"},"trusted":true},"outputs":[],"source":["from tensorflow.keras.preprocessing.image import img_to_array, load_img, array_to_img\n","# array_to_img(train_data[0][0])\n","len(train_data)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-21T15:04:37.451787Z","iopub.status.busy":"2024-08-21T15:04:37.450709Z","iopub.status.idle":"2024-08-21T15:43:10.995438Z","shell.execute_reply":"2024-08-21T15:43:10.993774Z","shell.execute_reply.started":"2024-08-21T15:04:37.451749Z"},"trusted":true},"outputs":[],"source":["# Train the SRGAN\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","from tensorflow.keras.callbacks import ModelCheckpoint\n","from tensorflow.keras.models import load_model\n","\n","# checkpoint = ModelCheckpoint('srgan_generator_best.keras', monitor='g_loss', verbose=1, save_best_only=True, mode='min')\n","\n","# generator = load_model('/kaggle/working/srgan_generator_epoch_1.h5')\n","\n","# warnings.filterwarnings(action='once')\n","train_srgan(generator, discriminator, srgan_model, epochs=10000, batch_size=4, train_data=train_data)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":5570893,"sourceId":9213035,"sourceType":"datasetVersion"},{"isSourceIdPinned":true,"modelId":106738,"modelInstanceId":82416,"sourceId":98237,"sourceType":"modelInstanceVersion"}],"dockerImageVersionId":30746,"isGpuEnabled":false,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.0"}},"nbformat":4,"nbformat_minor":4}
